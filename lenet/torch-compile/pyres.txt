/home/meng/torch-compiler/models/lenet/torch-compile/lenet_run.py:96: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
Layer conv1 output:
tensor([[[[-0.5239, -0.5203, -0.4859,  ..., -0.4480, -0.4298, -0.4626],
          [-0.5110, -0.1040,  0.2262,  ..., -0.4452, -0.4457, -0.4585],
          [ 0.4315,  1.1054,  1.3573,  ..., -0.4202, -0.4386, -0.4332],
          ...,
          [-0.4245, -0.4115, -0.3954,  ..., -0.5195, -0.4582, -0.3918],
          [-0.4273, -0.4194, -0.4292,  ..., -0.4600, -0.3952, -0.3536],
          [-0.4267, -0.4170, -0.4282,  ..., -0.4089, -0.3528, -0.3537]],

         [[-1.1974, -1.2546, -1.2364,  ..., -0.9030, -0.8913, -0.8919],
          [-1.7662, -1.6162, -1.4257,  ..., -0.9051, -0.9026, -0.9089],
          [-2.1040, -1.4582, -1.1188,  ..., -0.9029, -0.9211, -0.9346],
          ...,
          [-0.9381, -0.9492, -0.9708,  ..., -0.8944, -1.0236, -0.9372],
          [-0.9409, -0.9456, -0.9347,  ..., -0.9542, -1.0408, -0.9458],
          [-0.9362, -0.9448, -0.9385,  ..., -0.9622, -1.0013, -0.9424]],

         [[-0.5599, -0.5256, -0.4968,  ..., -0.6966, -0.7123, -0.7203],
          [-0.3050, -0.3066, -0.3771,  ..., -0.7074, -0.7141, -0.7218],
          [-0.0455, -0.0563, -0.2114,  ..., -0.7203, -0.7268, -0.7241],
          ...,
          [-0.7032, -0.6852, -0.5927,  ..., -0.8388, -0.6984, -0.6752],
          [-0.7029, -0.6842, -0.6335,  ..., -0.7470, -0.6612, -0.6436],
          [-0.6969, -0.6872, -0.6652,  ..., -0.7132, -0.6425, -0.6130]],

         [[-0.7676, -0.9135, -1.1281,  ..., -0.6756, -0.6697, -0.6568],
          [-1.2309, -1.7617, -2.2101,  ..., -0.6862, -0.6827, -0.6952],
          [-1.6554, -2.0162, -2.0089,  ..., -0.7142, -0.7011, -0.7079],
          ...,
          [-0.6914, -0.6947, -0.6653,  ..., -0.5940, -0.6814, -0.7241],
          [-0.6809, -0.6868, -0.6707,  ..., -0.6798, -0.6988, -0.7147],
          [-0.7015, -0.7022, -0.6946,  ..., -0.7214, -0.7145, -0.6826]],

         [[ 0.1699, -0.0668, -0.3241,  ...,  0.5032,  0.5145,  0.5286],
          [-0.5146, -0.9304, -1.2913,  ...,  0.5161,  0.4982,  0.5061],
          [-0.7260, -1.2892, -1.7306,  ...,  0.5092,  0.5019,  0.4954],
          ...,
          [ 0.4823,  0.4925,  0.5972,  ...,  0.4239,  0.4733,  0.4215],
          [ 0.4897,  0.4908,  0.5460,  ...,  0.4954,  0.5090,  0.4645],
          [ 0.4967,  0.4979,  0.5116,  ...,  0.4982,  0.5371,  0.5163]],

         [[-0.8090, -0.7993, -0.8519,  ..., -0.9693, -0.9760, -0.9762],
          [-0.6815, -0.7456, -0.7547,  ..., -0.9436, -0.9669, -0.9857],
          [-0.0584,  0.1621,  0.3279,  ..., -0.9608, -0.9375, -0.9337],
          ...,
          [-0.9397, -0.9533, -1.1163,  ..., -0.9304, -0.8375, -0.8184],
          [-0.9262, -0.9378, -1.0336,  ..., -1.0059, -0.9344, -0.8150],
          [-0.9515, -0.9538, -0.9796,  ..., -1.0060, -1.0142, -0.8950]]]])
--------------------------------------------------
Layer conv2 output:
tensor([[[[ -1.4734,  -0.8344,  -2.4170,  ...,  -1.5307,  -0.2047,  -0.5938],
          [ -9.8539, -10.1641, -11.9650,  ...,   3.1551,   0.8658,  -1.9621],
          [ -4.4999,  -5.8101,  -6.0198,  ...,   3.0681,   1.3460,  -0.5892],
          ...,
          [ -4.7756,  -8.4305, -12.5422,  ..., -10.9714,  -8.3230,  -3.8631],
          [ -0.2494,  -0.9202,  -3.8739,  ..., -15.0601,  -8.3590,   0.3157],
          [  2.3129,   2.4756,   2.4433,  ...,  -5.7125,  -3.8829,  -0.1806]],

         [[ -7.5273, -10.3970, -14.2917,  ...,  -6.1509,  -2.6967,  -4.5314],
          [  1.0221,  -0.4087,  -1.8327,  ...,  -2.2980,  -3.5012,  -5.0123],
          [ -4.6789,  -2.9946,   2.2191,  ...,  -8.1902, -11.6199,  -9.6642],
          ...,
          [ -1.7242,  -1.6450,  -0.2990,  ...,  -7.5857,  -3.7958,  -3.9421],
          [ -1.0976,  -4.4455,  -6.5848,  ...,  -1.9125,   0.3118,   0.0992],
          [ -0.0857,  -5.0602, -11.4630,  ...,  -0.2133,   0.9199,  -1.0094]],

         [[ -2.2599,  -5.0293,  -5.1431,  ...,  -6.1668,  -3.9194,  -0.8795],
          [ -1.8537,  -4.0000,  -8.0356,  ...,  -4.1343,  -0.0939,  -1.0009],
          [ -5.2336,  -4.0663,  -4.3816,  ...,  -6.4747,  -7.5328,  -5.9049],
          ...,
          [ -5.6451,  -7.0818, -10.2348,  ...,   2.0902,   1.2497,  -3.9995],
          [ -7.5937, -13.3642, -15.7391,  ...,  -8.2931,  -4.2406,  -0.7912],
          [  0.3842,  -3.4580,  -8.6965,  ...,  -9.7176,  -2.5763,   1.4379]],

         ...,

         [[ -2.0678,  -2.5496,   0.7453,  ...,  -6.3984,  -4.0259,  -2.3571],
          [ -2.3348,  -2.5538,  -2.3914,  ...,  -4.6344,  -4.0985,  -4.3348],
          [ -2.5924,  -2.2535,  -2.7564,  ...,  -3.9741,  -6.9702,  -5.9298],
          ...,
          [ -5.5335,  -6.4600,  -7.7224,  ...,   7.6756,   3.6121,  -4.6590],
          [ -3.4274,  -6.7629,  -6.7225,  ...,  -1.8961,   1.0511,  -3.5708],
          [  0.4259,  -4.4602,  -5.7864,  ...,  -7.2186,  -3.4605,  -1.6440]],

         [[  4.3836,   5.3716,   5.6623,  ...,   0.5122,  -0.3677,  -1.0792],
          [ -1.7366,  -2.0840,  -1.3217,  ...,   1.1476,   0.0189,  -0.2615],
          [ -3.7015,  -4.1364,  -8.2476,  ...,  -2.7241,  -1.7027,  -1.4247],
          ...,
          [ -2.7881,  -4.3292,  -5.4066,  ...,   4.7902,   4.1078,   1.0998],
          [ -3.1512,  -3.5199,  -5.0831,  ...,  -1.8861,   0.1956,  -0.1796],
          [ -3.1058,  -2.6169,  -1.4795,  ...,  -6.5319,  -3.4343,  -2.1144]],

         [[ -0.8003,  -1.5829,  -2.9805,  ..., -10.0679,  -7.3125,  -2.9267],
          [ -4.3369,  -2.8881,  -3.1072,  ...,  -9.2594,  -7.2277,  -4.4410],
          [ -3.7477,   0.1375,   0.7935,  ...,   2.8650,  -1.7061,  -3.5693],
          ...,
          [ -4.6114,  -8.6621,  -8.9919,  ...,  -3.9541,  -5.4709,  -8.6079],
          [  1.8761,  -2.8609,  -5.8633,  ...,  -8.9855,  -8.8813,  -8.9239],
          [  4.8872,   2.3539,   1.4799,  ...,  -7.4493,  -6.0012,  -3.5328]]]])
--------------------------------------------------
Layer fc1 output:
tensor([[ 1.0451e+01,  1.7324e+01, -2.9722e+01, -5.1967e+00, -1.0053e+01,
         -4.7738e+00, -2.1831e+01, -1.4057e+01, -1.8980e+01, -3.5888e+01,
         -3.0274e+01, -2.4984e+01,  1.6513e+01, -1.0461e+01, -2.2333e+01,
         -3.7612e+01,  2.6290e+00,  4.3617e+00, -2.3733e+01, -1.3228e+01,
          1.6777e+01, -2.6795e+01, -6.7194e+00,  2.5138e+00, -1.4609e+01,
          2.2108e+01,  2.2051e+00, -3.6658e+01, -6.7046e+00, -8.0575e+00,
         -1.8137e+01, -2.0661e+01, -1.4494e+01, -2.0319e+01,  4.3385e+00,
         -9.9103e+00, -1.7449e+01,  6.6714e+00,  2.5550e+01, -6.8929e+00,
         -7.2975e+00, -1.6094e+01,  9.9340e+00, -2.5649e+01, -2.4091e+01,
         -2.0266e+01,  1.2028e+01,  3.3664e+01, -5.4419e+00, -1.6087e+01,
         -1.2879e+01, -3.4613e+01, -1.8192e+01, -2.5426e+01, -1.2790e+01,
         -8.7897e+00, -2.2178e+01, -1.1666e+01, -2.6088e+01, -3.5201e+00,
         -3.6725e+01,  6.8196e+00, -1.6725e+01, -3.1464e+01, -3.6879e+01,
         -5.5161e+01, -5.6616e+00, -3.0951e+00, -2.1760e+00, -2.7098e+01,
         -3.1930e+01, -6.6671e+00,  1.3731e+01, -2.0195e+01, -1.2111e+01,
         -1.0816e+01, -9.9812e+00,  1.5354e+01, -3.9158e+00, -2.5454e+01,
         -2.6515e+01, -6.7466e+00, -6.8321e+00, -1.4357e+01,  2.4436e+00,
         -1.3469e+01, -3.5725e+01, -1.2185e+01, -1.8982e+01, -4.5280e+01,
         -6.4048e+00, -3.2953e+01, -2.5188e+01, -8.0336e+00,  9.1113e-03,
          5.5793e+00,  2.1460e+01, -3.0332e+01,  4.9934e+00,  2.0382e+01,
         -2.9089e+01, -1.8485e+01, -1.6916e+01, -3.4800e+01,  2.5009e+00,
         -4.2261e+00, -1.5983e+01, -2.8158e+01, -3.2854e+01, -3.9762e+01,
         -7.2822e+00, -4.1080e+00,  1.1358e+00, -2.7839e+01, -4.7411e+00,
         -1.1534e+01, -9.6553e+00, -1.6663e+01, -7.1412e+00, -1.4549e+01]])
--------------------------------------------------
Layer fc2 output:
tensor([[ 34.5192, -34.8664, -44.8286,  21.1893, -27.7178, -29.4884, -27.7414,
          27.1282, -14.9513, -42.1097, -49.4069, -42.9860, -10.7581, -51.6134,
          42.6770, -57.7642, -23.8605, -24.9262, -42.0508,  17.6357, -31.0185,
         -49.2298, -28.8555, -29.2051, -31.9002, -22.1182, -31.9974, -10.6184,
         -28.0837,   7.2824, -37.1636, -65.4265, -19.0901, -13.3720,  19.3579,
         -22.4790, -34.7320, -38.1221, -47.7975, -69.5396, -15.2309, -50.9280,
         -24.2632, -32.7077,  23.8686, -28.0760, -49.9291, -29.9367, -64.6809,
         -48.4455, -20.2143, -64.4551, -37.9178, -40.8431,  43.8581,  30.5571,
         -60.6647,  29.3879,  37.8705,   0.7436, -21.6872, -49.7235, -66.9689,
          -0.6752, -10.8064,  -9.5683, -73.5451, -16.9247, -15.6327, -39.8267,
         -43.0651, -19.0172, -28.6662, -26.2513, -45.1314, -30.4674, -66.6970,
         -43.8204,   1.8140, -51.9195, -53.3851, -37.4188, -29.5265, -13.8564]])
--------------------------------------------------
Layer fc3 output:
tensor([[ -98.6182,  -68.1098,  -55.6942,   41.2719, -122.3341,  -39.0987,
         -109.2420,  -88.9960,  -42.6719,  -50.4501]])
--------------------------------------------------
预测的数字是: 3
结果矩阵: 
[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
